{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhoenixStormJr/Colab-AI-enhance-video-CPU-only/blob/main/Image_Enhancement_with_Real_ESRGAN_Phoenix_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup only. For ESRGAN\n",
        "# @markdown This is extremely long setup code. I don't reccomend viewing it unless you're a geek, and like that stuff.\n",
        "import os\n",
        "#changed install to fix error.\n",
        "#https://www.patreon.com/posts/for-people-error-100361567\n",
        "if(not os.path.exists(\"/usr/local/lib/python3.10/dist-packages/gfpgan\")):\n",
        "  !pip uninstall torch xformers -y\n",
        "  !pip install torch==2.0.1 torchvision==0.15.2 --extra-index-url https://download.pytorch.org/whl/cu118 xformers==0.0.21 torchaudio basicsr gfpgan --quiet\n",
        "\n",
        "\n",
        "\n",
        "#@title Now run this next cell to import all necessary packages:\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import queue\n",
        "import threading\n",
        "import torch\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torch import nn as nn\n",
        "from PIL import Image\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from math import ceil, floor, sqrt\n",
        "from PIL import Image, ImageFilter\n",
        "from IPython.display import Image as display_image\n",
        "\n",
        "\n",
        "\n",
        "#@title Utilities\n",
        "#These are the Utils functions and the classes containing the actual model architecture:\n",
        "# Utils\n",
        "# ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "\n",
        "def convert_to_jpg(input_path, output_path):\n",
        "    # Open the PNG file\n",
        "    with Image.open(input_path) as img:\n",
        "        # Save the image in JPEG format\n",
        "        img.convert(\"RGB\").save(output_path, 'JPEG')\n",
        "\n",
        "\n",
        "class RealESRGANer():\n",
        "    \"\"\"A helper class for upsampling images with RealESRGAN.\n",
        "\n",
        "    Args:\n",
        "        scale (int): Upsampling scale factor used in the networks. It is usually 2 or 4.\n",
        "        model_path (str): The path to the pretrained model. It can be urls (will first download it automatically).\n",
        "        model (nn.Module): The defined network. Default: None.\n",
        "        tile (int): As too large images result in the out of GPU memory issue, so this tile option will first crop\n",
        "            input images into tiles, and then process each of them. Finally, they will be merged into one image.\n",
        "            0 denotes for do not use tile. Default: 0.\n",
        "        tile_pad (int): The pad size for each tile, to remove border artifacts. Default: 10.\n",
        "        pre_pad (int): Pad the input images to avoid border artifacts. Default: 10.\n",
        "        half (float): Whether to use half precision during inference. Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 scale,\n",
        "                 model_path,\n",
        "                 model=None,\n",
        "                 tile=0,\n",
        "                 tile_pad=10,\n",
        "                 pre_pad=10,\n",
        "                 half=False,\n",
        "                 device=None,\n",
        "                 gpu_id=None):\n",
        "        self.scale = scale\n",
        "        self.tile_size = tile\n",
        "        self.tile_pad = tile_pad\n",
        "        self.pre_pad = pre_pad\n",
        "        self.mod_scale = None\n",
        "        self.half = half\n",
        "\n",
        "        # initialize model\n",
        "        if gpu_id:\n",
        "            self.device = torch.device(\n",
        "                f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
        "        else:\n",
        "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
        "        # if the model_path starts with https, it will first download models to the folder: realesrgan/weights\n",
        "        # if model_path.startswith('https://'):\n",
        "        #     model_path = load_file_from_url(\n",
        "        #         url=model_path, model_dir='realesrgan/weights')\n",
        "        loadnet = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "        # prefer to use params_ema\n",
        "        if 'params_ema' in loadnet:\n",
        "            keyname = 'params_ema'\n",
        "        else:\n",
        "            keyname = 'params'\n",
        "        model.load_state_dict(loadnet[keyname], strict=True)\n",
        "        model.eval()\n",
        "        self.model = model.to(self.device)\n",
        "        if self.half:\n",
        "            self.model = self.model.half()\n",
        "\n",
        "    def pre_process(self, img):\n",
        "        \"\"\"Pre-process, such as pre-pad and mod pad, so that the images can be divisible\n",
        "        \"\"\"\n",
        "        img = torch.from_numpy(np.transpose(img, (2, 0, 1))).float()\n",
        "        self.img = img.unsqueeze(0).to(self.device)\n",
        "        if self.half:\n",
        "            self.img = self.img.half()\n",
        "\n",
        "        # pre_pad\n",
        "        if self.pre_pad != 0:\n",
        "            self.img = F.pad(self.img, (0, self.pre_pad, 0, self.pre_pad), 'reflect')\n",
        "        # mod pad for divisible borders\n",
        "        if self.scale == 2:\n",
        "            self.mod_scale = 2\n",
        "        elif self.scale == 1:\n",
        "            self.mod_scale = 4\n",
        "        if self.mod_scale is not None:\n",
        "            self.mod_pad_h, self.mod_pad_w = 0, 0\n",
        "            _, _, h, w = self.img.size()\n",
        "            if (h % self.mod_scale != 0):\n",
        "                self.mod_pad_h = (self.mod_scale - h % self.mod_scale)\n",
        "            if (w % self.mod_scale != 0):\n",
        "                self.mod_pad_w = (self.mod_scale - w % self.mod_scale)\n",
        "            self.img = F.pad(self.img, (0, self.mod_pad_w, 0, self.mod_pad_h), 'reflect')\n",
        "\n",
        "    def process(self):\n",
        "        # model inference\n",
        "        self.output = self.model(self.img)\n",
        "\n",
        "    def tile_process(self):\n",
        "        \"\"\"It will first crop input images to tiles, and then process each tile.\n",
        "        Finally, all the processed tiles are merged into one images.\n",
        "\n",
        "        Modified from: https://github.com/ata4/esrgan-launcher\n",
        "        \"\"\"\n",
        "        batch, channel, height, width = self.img.shape\n",
        "        output_height = height * self.scale\n",
        "        output_width = width * self.scale\n",
        "        output_shape = (batch, channel, output_height, output_width)\n",
        "\n",
        "        # start with black image\n",
        "        self.output = self.img.new_zeros(output_shape)\n",
        "        tiles_x = math.ceil(width / self.tile_size)\n",
        "        tiles_y = math.ceil(height / self.tile_size)\n",
        "\n",
        "        # loop over all tiles\n",
        "        for y in range(tiles_y):\n",
        "            for x in range(tiles_x):\n",
        "                # extract tile from input image\n",
        "                ofs_x = x * self.tile_size\n",
        "                ofs_y = y * self.tile_size\n",
        "                # input tile area on total image\n",
        "                input_start_x = ofs_x\n",
        "                input_end_x = min(ofs_x + self.tile_size, width)\n",
        "                input_start_y = ofs_y\n",
        "                input_end_y = min(ofs_y + self.tile_size, height)\n",
        "\n",
        "                # input tile area on total image with padding\n",
        "                input_start_x_pad = max(input_start_x - self.tile_pad, 0)\n",
        "                input_end_x_pad = min(input_end_x + self.tile_pad, width)\n",
        "                input_start_y_pad = max(input_start_y - self.tile_pad, 0)\n",
        "                input_end_y_pad = min(input_end_y + self.tile_pad, height)\n",
        "\n",
        "                # input tile dimensions\n",
        "                input_tile_width = input_end_x - input_start_x\n",
        "                input_tile_height = input_end_y - input_start_y\n",
        "                tile_idx = y * tiles_x + x + 1\n",
        "                input_tile = self.img[:, :, input_start_y_pad:input_end_y_pad, input_start_x_pad:input_end_x_pad]\n",
        "\n",
        "                # upscale tile\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        output_tile = self.model(input_tile)\n",
        "                except RuntimeError as error:\n",
        "                    print('Error', error)\n",
        "                print(f'\\tTile {tile_idx}/{tiles_x * tiles_y}')\n",
        "\n",
        "                # output tile area on total image\n",
        "                output_start_x = input_start_x * self.scale\n",
        "                output_end_x = input_end_x * self.scale\n",
        "                output_start_y = input_start_y * self.scale\n",
        "                output_end_y = input_end_y * self.scale\n",
        "\n",
        "                # output tile area without padding\n",
        "                output_start_x_tile = (input_start_x - input_start_x_pad) * self.scale\n",
        "                output_end_x_tile = output_start_x_tile + input_tile_width * self.scale\n",
        "                output_start_y_tile = (input_start_y - input_start_y_pad) * self.scale\n",
        "                output_end_y_tile = output_start_y_tile + input_tile_height * self.scale\n",
        "\n",
        "                # put tile into output image\n",
        "                self.output[:, :, output_start_y:output_end_y,\n",
        "                            output_start_x:output_end_x] = output_tile[:, :, output_start_y_tile:output_end_y_tile,\n",
        "                                                                       output_start_x_tile:output_end_x_tile]\n",
        "\n",
        "    def post_process(self):\n",
        "        # remove extra pad\n",
        "        if self.mod_scale is not None:\n",
        "            _, _, h, w = self.output.size()\n",
        "            self.output = self.output[:, :, 0:h - self.mod_pad_h * self.scale, 0:w - self.mod_pad_w * self.scale]\n",
        "        # remove prepad\n",
        "        if self.pre_pad != 0:\n",
        "            _, _, h, w = self.output.size()\n",
        "            self.output = self.output[:, :, 0:h - self.pre_pad * self.scale, 0:w - self.pre_pad * self.scale]\n",
        "        return self.output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def enhance(self, img, outscale=None, alpha_upsampler='realesrgan'):\n",
        "        h_input, w_input = img.shape[0:2]\n",
        "        # img: numpy\n",
        "        img = img.astype(np.float32)\n",
        "        if np.max(img) > 256:  # 16-bit image\n",
        "            max_range = 65535\n",
        "            print('\\tInput is a 16-bit image')\n",
        "        else:\n",
        "            max_range = 255\n",
        "        img = img / max_range\n",
        "        if len(img.shape) == 2:  # gray image\n",
        "            img_mode = 'L'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "        elif img.shape[2] == 4:  # RGBA image with alpha channel\n",
        "            img_mode = 'RGBA'\n",
        "            alpha = img[:, :, 3]\n",
        "            img = img[:, :, 0:3]\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                alpha = cv2.cvtColor(alpha, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            img_mode = 'RGB'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ------------------- process image (without the alpha channel) ------------------- #\n",
        "        self.pre_process(img)\n",
        "        if self.tile_size > 0:\n",
        "            self.tile_process()\n",
        "        else:\n",
        "            self.process()\n",
        "        output_img = self.post_process()\n",
        "        output_img = output_img.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "        output_img = np.transpose(output_img[[2, 1, 0], :, :], (1, 2, 0))\n",
        "        if img_mode == 'L':\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # ------------------- process the alpha channel if necessary ------------------- #\n",
        "        if img_mode == 'RGBA':\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                self.pre_process(alpha)\n",
        "                if self.tile_size > 0:\n",
        "                    self.tile_process()\n",
        "                else:\n",
        "                    self.process()\n",
        "                output_alpha = self.post_process()\n",
        "                output_alpha = output_alpha.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "                output_alpha = np.transpose(output_alpha[[2, 1, 0], :, :], (1, 2, 0))\n",
        "                output_alpha = cv2.cvtColor(output_alpha, cv2.COLOR_BGR2GRAY)\n",
        "            else:  # use the cv2 resize for alpha channel\n",
        "                h, w = alpha.shape[0:2]\n",
        "                output_alpha = cv2.resize(alpha, (w * self.scale, h * self.scale), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            # merge the alpha channel\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2BGRA)\n",
        "            output_img[:, :, 3] = output_alpha\n",
        "\n",
        "        # ------------------------------ return ------------------------------ #\n",
        "        if max_range == 65535:  # 16-bit image\n",
        "            output = (output_img * 65535.0).round().astype(np.uint16)\n",
        "        else:\n",
        "            output = (output_img * 255.0).round().astype(np.uint8)\n",
        "\n",
        "        if outscale is not None and outscale != float(self.scale):\n",
        "            output = cv2.resize(\n",
        "                output, (\n",
        "                    int(w_input * outscale),\n",
        "                    int(h_input * outscale),\n",
        "                ), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "        return output, img_mode\n",
        "\n",
        "\n",
        "class PrefetchReader(threading.Thread):\n",
        "    \"\"\"Prefetch images.\n",
        "\n",
        "    Args:\n",
        "        img_list (list[str]): A image list of image paths to be read.\n",
        "        num_prefetch_queue (int): Number of prefetch queue.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_list, num_prefetch_queue):\n",
        "        super().__init__()\n",
        "        self.que = queue.Queue(num_prefetch_queue)\n",
        "        self.img_list = img_list\n",
        "\n",
        "    def run(self):\n",
        "        for img_path in self.img_list:\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            self.que.put(img)\n",
        "\n",
        "        self.que.put(None)\n",
        "\n",
        "    def __next__(self):\n",
        "        next_item = self.que.get()\n",
        "        if next_item is None:\n",
        "            raise StopIteration\n",
        "        return next_item\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "\n",
        "class IOConsumer(threading.Thread):\n",
        "\n",
        "    def __init__(self, opt, que, qid):\n",
        "        super().__init__()\n",
        "        self._queue = que\n",
        "        self.qid = qid\n",
        "        self.opt = opt\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            msg = self._queue.get()\n",
        "            if isinstance(msg, str) and msg == 'quit':\n",
        "                break\n",
        "\n",
        "            output = msg['output']\n",
        "            save_path = msg['save_path']\n",
        "            cv2.imwrite(save_path, output)\n",
        "        print(f'IO worker {self.qid} is done.')\n",
        "\n",
        "\n",
        "def FileExtension(FileName):\n",
        "  return FileName.split(\".\")[-1]\n",
        "\n",
        "#@title Main Code\n",
        "# And this is the main method to use to enhance our images:\n",
        "def enhance_image(input_file, layers=2, upscale=2, final_filename=\"\", enhance_faces=False):\n",
        "  ## Set models to use\n",
        "  if layers == 4:\n",
        "    # 4 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "    netscale = 4\n",
        "    model_file = 'RealESRGAN_x4plus.pth'\n",
        "  elif layers == 2:\n",
        "    # 2 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
        "    netscale = 2\n",
        "    model_file = 'RealESRGAN_x2plus.pth'\n",
        "  else:\n",
        "    print(\"Layers parameter must be either 2 or 4.\")\n",
        "    return\n",
        "  # Final enhanced image will be upscaled by this factor using LANCZOS4 resampling\n",
        "  # Input image\n",
        "  imgname, org_extension = input_file.split('.')\n",
        "  image = cv2.imread(input_file)\n",
        "  org_width, org_height = image.shape[:2]\n",
        "  # Compute tile size\n",
        "  if min(org_width, org_height) <= 800:\n",
        "    tile_size = 0\n",
        "    print(f\"Small image so batching is not necessary.\")\n",
        "  else:\n",
        "    tile_size = ceil(sqrt(min(org_width, org_height))) * 10\n",
        "  if tile_size > 500:\n",
        "    tile_size = 350\n",
        "  print(f\"Tile size being used: {tile_size}\")\n",
        "  # restorer\n",
        "  upsampler = RealESRGANer(\n",
        "      scale=netscale,\n",
        "      model_path=model_file,\n",
        "      model=model,\n",
        "      tile=tile_size,\n",
        "      tile_pad=2,\n",
        "      half=False)\n",
        "  # Use GFPGAN for face enhancement\n",
        "  if enhance_faces:\n",
        "    from gfpgan import GFPGANer\n",
        "    face_enhancer = GFPGANer(\n",
        "        model_path='GFPGANv1.4.pth',\n",
        "        upscale=upscale,\n",
        "        arch='clean',\n",
        "        channel_multiplier=2,\n",
        "        bg_upsampler=upsampler)\n",
        "  img = cv2.imread(input_file, cv2.IMREAD_UNCHANGED)\n",
        "  try:\n",
        "    if enhance_faces:\n",
        "      _, _, output = face_enhancer.enhance(img, has_aligned=False, only_center_face=False, paste_back=True)\n",
        "    else:\n",
        "      output, _ = upsampler.enhance(img, outscale=upscale)\n",
        "  except RuntimeError as error:\n",
        "      print('Error', error)\n",
        "      print('If you encounter CUDA out of memory, try to set --tile with a smaller number.')\n",
        "      print('Else, the file you are using may be too large.')\n",
        "  else:\n",
        "    if final_filename != \"\":\n",
        "      save_path = final_filename\n",
        "    else:\n",
        "      save_path = f'{imgname}_out.{FileExtension(input_file)}'\n",
        "    cv2.imwrite(save_path, output)\n",
        "    print(f\"Enhanced image has been saved to {save_path}.\\nClick refresh button on the left panel to get latest version of {save_path}\")\n",
        "    return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Metrics Code\n",
        "# These are some helper fucntions to compute the quality of images based on certain metrics like resolution, sharpness, contrast, and noise:\n",
        "def get_resolution(image):\n",
        "    return image.shape[:2]\n",
        "\n",
        "def get_noise_level(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute the Discrete Fourier Transform (DFT)\n",
        "    f_transform = np.fft.fft2(gray)\n",
        "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "\n",
        "    # Compute the magnitude spectrum\n",
        "    magnitude_spectrum = np.abs(f_transform_shifted)\n",
        "\n",
        "    # Calculate the noise level using the standard deviation of the magnitude spectrum\n",
        "    noise_level = np.std(np.log1p(magnitude_spectrum))\n",
        "\n",
        "    return round(noise_level, 2)\n",
        "\n",
        "def get_sharpness(image):\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    # Apply an edge-enhancing filter (Laplacian) and compute variance as a measure of sharpness\n",
        "    laplacian = cv2.Laplacian(cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2GRAY), cv2.CV_64F)\n",
        "    return round(laplacian.var(), 2)\n",
        "\n",
        "def get_contrast(image):\n",
        "    # Using Michelson contrast measure\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    I_max = np.max(gray)\n",
        "    I_min = np.min(gray)\n",
        "    print(I_min, I_max)\n",
        "\n",
        "    contrast = (I_max - I_min) / (I_max + I_min)\n",
        "    return round(contrast, 5)\n",
        "\n",
        "\n",
        "def get_filesize(image_file):\n",
        "  file_size = os.path.getsize(image_file)\n",
        "  return round(file_size / 1_000_000, 2)\n",
        "\n",
        "\n",
        "import time\n",
        "class Timer:\n",
        "    def __init__(self) -> None:\n",
        "        self.start = 0\n",
        "        self.end = 0\n",
        "\n",
        "    def start(self):\n",
        "        self.start = time.time()\n",
        "\n",
        "    def end(self):\n",
        "        self.end = time.time()\n",
        "        elapsed_time = self.end - self.start\n",
        "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
        "\n",
        "\n",
        "def print_quality(image_file):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_file)\n",
        "\n",
        "    # Get image metrics\n",
        "    resolution = get_resolution(image)\n",
        "    noise_level = get_noise_level(image)\n",
        "    sharpness = get_sharpness(image)\n",
        "    try:\n",
        "      contrast = get_contrast(image)\n",
        "    except:\n",
        "      contrast = \"unknown\"\n",
        "    image_size = get_filesize(image_file)\n",
        "\n",
        "    # Output the results\n",
        "    print(f\"Resolution: {resolution} pixels\")\n",
        "    print(f\"Noise Level: {noise_level} dB\")\n",
        "    print(f\"Sharpness: {sharpness}\")\n",
        "    print(f\"Contrast: {contrast}\")\n",
        "    print(f\"Size of image: {image_size} MB\")"
      ],
      "metadata": {
        "id": "mIznOMeCrCSq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Here we go woohoo :)\n",
        "#@markdown Ok so now you can run the code cell below and scroll a little down to below the code cell. It will prompt you to upload an image file. After it is uploaded, it will enhance your image and display it for you.\n",
        "#@markdown\n",
        "#@markdown You can change the values of \"layers\" and \"enhance_faces\" in the actual method below which has been cordoned off for you! ;)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Model = 'RealESRGAN_x2plus.pth (default) (For General Images)' # @param [\"RealESRGAN_x2plus.pth (default) (For General Images)\", \"RealESRGAN_x4plus.pth (For General Images)\", \"RealESRNet_x4plus.pth (X4 model with MSE loss (over-smooth effects))\", \"ESRGAN_SRx4_DF2KOST_official-ff704c30.pth (official ESRGAN model)\", \"RealESRGAN_x4plus_netD.pth (fine-tuning)\", \"RealESRGAN_x2plus_netD.pth (fine-tuning)\", \"RealESRGAN_x4plus_anime_6B.pth (for anime images)\", \"RealESRGAN_x4plus_anime_6B_netD.pth (fine-tuning anime images)\", \"realesr-animevideov3.pth (For Animation Videos)\"]\n",
        "#@markdown Choose either 2 or 4 as the value here.\n",
        "layers = \"2\" # @param [2, 4]\n",
        "layers = int(layers)\n",
        "#@markdown This value indicates the number of times the output image's resolution needs to enlarged from the original.\n",
        "upscale = 1.5 # @param {type:\"number\"}\n",
        "#@markdown I honestly don't know what this does. enhance the faces of the characters?\n",
        "enhance_faces=True # @param {type:\"boolean\"}\n",
        "Display_Images=True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def DisplayImage(imagePath):\n",
        "  img = mpimg.imread(imagePath) #Replace \"image.jpg\" with the path of your image\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def enhanceImage2(filename, outputFilename, layers, upscale, enhance_faces):\n",
        "  # Start timing\n",
        "  t = Timer()\n",
        "  t.start\n",
        "  ########################################################################################################################################################\n",
        "  result = enhance_image(input_file=filename, layers=layers, upscale=upscale, final_filename=outputFilename, enhance_faces=enhance_faces)\n",
        "  ########################################################################################################################################################\n",
        "  print(f\"result: {result}\")\n",
        "  t.end # End timing\n",
        "  if(Display_Images):\n",
        "    print(filename)\n",
        "    DisplayImage(filename)\n",
        "    print(outputFilename)\n",
        "    DisplayImage(outputFilename)\n",
        "\n",
        "\n",
        "%cd /content\n",
        "if(Model == 'RealESRGAN_x2plus.pth (default) (For General Images)' and (not os.path.exists(\"/content/RealESRGAN_x2plus.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth\n",
        "if(Model == 'RealESRGAN_x4plus.pth (For General Images)' and (not os.path.exists(\"//content/RealESRGAN_x4plus.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
        "if(Model == 'RealESRNet_x4plus.pth (X4 model with MSE loss (over-smooth effects))' and (not os.path.exists(\"/RealESRNet_x4plus.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.1/RealESRNet_x4plus.pth\n",
        "if(Model == 'ESRGAN_SRx4_DF2KOST_official-ff704c30.pth (official ESRGAN model)' and (not os.path.exists(\"/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.1/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth\n",
        "if(Model == 'RealESRGAN_x4plus_netD.pth (fine-tuning)' and (not os.path.exists(\"/RealESRGAN_x4plus_netD.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.3/RealESRGAN_x4plus_netD.pth\n",
        "if(Model == 'RealESRGAN_x2plus_netD.pth (fine-tuning)' and (not os.path.exists(\"/RealESRGAN_x2plus_netD.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.3/RealESRGAN_x2plus_netD.pth\n",
        "if(Model == 'RealESRGAN_x4plus_anime_6B.pth (for anime images)' and (not os.path.exists(\"/RealESRGAN_x4plus_anime_6B.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\n",
        "if(Model == 'RealESRGAN_x4plus_anime_6B_netD.pth (fine-tuning anime images)' and (not os.path.exists(\"/RealESRGAN_x4plus_anime_6B_netD.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B_netD.pth\n",
        "if(Model == 'realesr-animevideov3.pth (For Animation Videos)' and (not os.path.exists(\"/realesr-animevideov3.pth\"))):\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-animevideov3.pth\n",
        "\n",
        "if(not os.path.exists(\"/content/GFPGANv1.4.pth\")):\n",
        "  !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\n",
        "\n",
        "\n",
        "\n",
        "# Upload a file\n",
        "uploaded = files.upload()\n",
        "# Get the file name\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"File uploaded: {filename}\")\n",
        "Image.MAX_IMAGE_PIXELS = 933120000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "enhanceImage2(filename,f\"{filename.split('.')[0]}_upscaled.{FileExtension(filename)}\",layers,upscale,enhance_faces)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uTPGERzujrMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title pure debugging. This cell is useless.\n",
        "import os\n",
        "if(not os.path.exists(\"/usr/local/lib/python3.10/dist-packages/colabxterm\")):\n",
        "  !pip install colab-xterm\n",
        "  %load_ext colabxterm\n",
        "%xterm"
      ],
      "metadata": {
        "id": "8532m4mFxhV_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}