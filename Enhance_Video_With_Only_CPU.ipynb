{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhoenixStormJr/Unfinished-Colab-AI-enhance-video/blob/main/Enhance_Video_With_Only_CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZfMpqG445Ah",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title establish session, upload video, get .wav, framerate, and split video into frames\n",
        "#@markdown if you would like to start over, delete the folder \"UpscaleVideo\" in your google drive.\n",
        "#@markdown\n",
        "#@markdown Make sure before running the master session, UpscaleVideo/MergeSessions is deleted\n",
        "%cd /content\n",
        "#@markdown Mounting google drive also automatically combines sessions. Use multiple sessions to super speed the time!\n",
        "MountGoogleDrive = True # @param {type:\"boolean\"}\n",
        "#@markdown In case you're having errors or glitches, you can force this to be the master session by checking this box\n",
        "ForceMasterSession = False # @param {type:\"boolean\"}\n",
        "\n",
        "format = \"png\" # @param [\"png\", \"jpg\", \"tga\", \"tiff\", \"webp\"]\n",
        "\n",
        "MergeSessionsPath = \"/content/drive/MyDrive/UpscaleVideo/MergeSessions\"\n",
        "OriginalOutputPath = \"/content/OriginalOutput\"\n",
        "UpscaledOutputPath = \"/content/drive/MyDrive/UpscaleVideo/UpscaledOutput\"\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "  import os\n",
        "  global session\n",
        "  session = 0\n",
        "  if(os.path.exists(\"/content/sessionNumber.txt\")):\n",
        "    session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "    print(\"Session already established.\")\n",
        "    if(session == 1):\n",
        "      print(\"This is the master session.\")\n",
        "    else:\n",
        "      print(f\"This is an assist session {session}.\")\n",
        "  if((MountGoogleDrive) and (not os.path.exists(\"/content/drive/MyDrive\"))):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    if(not os.path.exists(f\"{MergeSessionsPath}/setup\")):\n",
        "      os.makedirs(f\"{MergeSessionsPath}/setup\")\n",
        "    if(not os.path.exists(\"/content/sessionNumber.txt\")):\n",
        "      if(ForceMasterSession):\n",
        "        !rm -r {MergeSessionsPath}/setup\n",
        "        os.makedirs(f\"{MergeSessionsPath}/setup\")\n",
        "        !rm -r {MergeSessionsPath}/ToProcess\n",
        "      if((not os.path.exists(f\"{MergeSessionsPath}/MasterSessionTaken.txt\")) or (ForceMasterSession)):\n",
        "        print()\n",
        "        print()\n",
        "        print(\"MergeSessionsPath/setup contains this:\")\n",
        "        print()\n",
        "        print(os.listdir(f\"{MergeSessionsPath}\"))\n",
        "        f = open(f\"{MergeSessionsPath}/MasterSessionTaken.txt\", \"w\")\n",
        "        f.close()\n",
        "        session = 1\n",
        "        open(\"/content/sessionNumber.txt\",\"w\").write(str(session))\n",
        "        print(f\"SESSION IS: {session}, AKA the master session.\")\n",
        "        print()\n",
        "        print()\n",
        "        print(\"After establishing session, MergeSessionsPath contains this:\")\n",
        "        print()\n",
        "        print(os.listdir(f\"{MergeSessionsPath}\"))\n",
        "      else:\n",
        "        x = 2\n",
        "        while(os.path.exists(f\"{MergeSessionsPath}/setup/Session{x}Taken.txt\")):\n",
        "          x = x + 1\n",
        "        print()\n",
        "        print()\n",
        "        print(\"MergeSessionsPath/setup contains this:\")\n",
        "        print()\n",
        "        print(os.listdir(f\"{MergeSessionsPath}/setup\"))\n",
        "        f = open(f\"{MergeSessionsPath}/setup/Session{x}Taken.txt\", \"w\")\n",
        "        f.close()\n",
        "        session = x\n",
        "        open(\"/content/sessionNumber.txt\",\"w\").write(str(session))\n",
        "        print(f\"SESSION IS {session} AKA an assist session.\")\n",
        "        print()\n",
        "        print()\n",
        "        print(\"After establishing session, MergeSessionsPath/setup contains this:\")\n",
        "        print()\n",
        "        print(os.listdir(f\"{MergeSessionsPath}/setup\"))\n",
        "  from google.colab import files\n",
        "  import os\n",
        "\n",
        "  if(not os.path.exists(\"/content/drive/MyDrive/UpscaleVideo\")):\n",
        "    os.makedirs(\"/content/drive/MyDrive/UpscaleVideo\")\n",
        "  if(not os.path.exists(\"/content/drive/MyDrive/UpscaleVideo/OriginalOutput.zip\")):\n",
        "    if(not os.path.exists(OriginalOutputPath)):\n",
        "      os.makedirs(OriginalOutputPath)\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded)[0]\n",
        "    !rm /content/input.mp4\n",
        "    os.rename(filename, \"/content/input.mp4\")\n",
        "    filename2 = filename.replace(\" \",\"_\").replace(\"(\",\"_\").replace(\")\",\"_\")\n",
        "    print(filename2)\n",
        "    !ffmpeg -i input.mp4 /content/drive/MyDrive/UpscaleVideo/audio.wav\n",
        "    FrameRate1 = !ffmpeg -i \"/content/input.mp4\" 2>&1 | sed -n \"s/.*, \\(.*\\) tbr.*/\\1/p\"\n",
        "    print(FrameRate1)\n",
        "    for thing in FrameRate1:\n",
        "      FrameRate = int(thing)\n",
        "    open(\"/content/drive/MyDrive/UpscaleVideo/Framerate.txt\", \"w\").write(str(FrameRate))\n",
        "    #I have to zip it, because google drive only shares a few files at a time.\n",
        "    !ffmpeg -i input.mp4 {OriginalOutputPath}/%07d.{format}\n",
        "    !zip -r /content/drive/MyDrive/UpscaleVideo/OriginalOutput.zip {OriginalOutputPath}\n",
        "  elif(not os.path.exists(OriginalOutputPath)):\n",
        "    !cp /content/drive/MyDrive/UpscaleVideo/OriginalOutput.zip /OriginalOutput.zip\n",
        "    %cd /\n",
        "    !unzip OriginalOutput.zip\n",
        "    %cd /content\n",
        "  if(session == 1):\n",
        "    print(f\"Session is {session}, AKA the MASTER SESSION.\")\n",
        "  else:\n",
        "    print(f\"Session is {session}, AKA an assist session.\")\n",
        "\n",
        "try:\n",
        "  main()\n",
        "except KeyboardInterrupt:\n",
        "  print('Interrupted')\n",
        "  session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "  if(session > 1):\n",
        "    !rm {MergeSessionsPath}/setup/Session{session}Taken.txt\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated this colab notebook. Sending message to main notebook it is closed.\")\n",
        "  else:\n",
        "    !rm {MergeSessionsPath}/MasterSessionTaken.txt\n",
        "    !rm -r {MergeSessionsPath}/setup\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated the main colab notebook. Terminating all others...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup only. For ESRGAN\n",
        "# @markdown This is extremely long setup code. I don't reccomend viewing it unless you're a geek, and like that stuff.\n",
        "\n",
        "MergeSessionsPath = \"/content/drive/MyDrive/UpscaleVideo/MergeSessions\"\n",
        "OriginalOutputPath = \"/content/OriginalOutput\"\n",
        "UpscaledOutputPath = \"/content/drive/MyDrive/UpscaleVideo/UpscaledOutput\"\n",
        "\n",
        "\n",
        "def main():\n",
        "  import os\n",
        "  #changed install to fix error.\n",
        "  #https://www.patreon.com/posts/for-people-error-100361567\n",
        "  if(not os.path.exists(\"/usr/local/lib/python3.10/dist-packages/torchaudio-2.0.2+cu118.dist-info\")):\n",
        "    !pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "  if(not os.path.exists(\"/usr/local/lib/python3.10/dist-packages/xformers-0.0.21.dist-info\")):\n",
        "    !pip install xformers==0.0.21\n",
        "    !pip install basicsr\n",
        "  if(not os.path.exists(\"/usr/local/lib/python3.10/dist-packages/gfpgan\")):\n",
        "    !pip install gfpgan\n",
        "#@title Now run this next cell to import all necessary packages:\n",
        "def kill():\n",
        "  print('Interrupted')\n",
        "  session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "  if(session > 1):\n",
        "    !rm {MergeSessionsPath}/setup/Session{session}Taken.txt\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated this colab notebook. Sending message to main notebook it is closed.\")\n",
        "  else:\n",
        "    !rm {MergeSessionsPath}/MasterSessionTaken.txt\n",
        "    !rm -r {MergeSessionsPath}/setup\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated the main colab notebook. Terminating all others...\")\n",
        "\n",
        "try:\n",
        "  main()\n",
        "except KeyboardInterrupt:\n",
        "  kill()\n",
        "except OSError:\n",
        "  kill()\n",
        "except ModuleNotFoundError:\n",
        "  kill()\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import queue\n",
        "import threading\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch import nn as nn\n",
        "from PIL import Image\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from math import ceil, floor, sqrt\n",
        "from PIL import Image, ImageFilter\n",
        "from IPython.display import Image as display_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#The rest of this stuff is just functions. Don't worry about it.\n",
        "#@title Utilities\n",
        "#These are the Utils functions and the classes containing the actual model architecture:\n",
        "# Utils\n",
        "# ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "\n",
        "def convert_to_jpg(input_path, output_path):\n",
        "    # Open the PNG file\n",
        "    with Image.open(input_path) as img:\n",
        "        # Save the image in JPEG format\n",
        "        img.convert(\"RGB\").save(output_path, 'JPEG')\n",
        "\n",
        "\n",
        "class RealESRGANer():\n",
        "    \"\"\"A helper class for upsampling images with RealESRGAN.\n",
        "\n",
        "    Args:\n",
        "        scale (int): Upsampling scale factor used in the networks. It is usually 2 or 4.\n",
        "        model_path (str): The path to the pretrained model. It can be urls (will first download it automatically).\n",
        "        model (nn.Module): The defined network. Default: None.\n",
        "        tile (int): As too large images result in the out of GPU memory issue, so this tile option will first crop\n",
        "            input images into tiles, and then process each of them. Finally, they will be merged into one image.\n",
        "            0 denotes for do not use tile. Default: 0.\n",
        "        tile_pad (int): The pad size for each tile, to remove border artifacts. Default: 10.\n",
        "        pre_pad (int): Pad the input images to avoid border artifacts. Default: 10.\n",
        "        half (float): Whether to use half precision during inference. Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 scale,\n",
        "                 model_path,\n",
        "                 model=None,\n",
        "                 tile=0,\n",
        "                 tile_pad=10,\n",
        "                 pre_pad=10,\n",
        "                 half=False,\n",
        "                 device=None,\n",
        "                 gpu_id=None):\n",
        "        self.scale = scale\n",
        "        self.tile_size = tile\n",
        "        self.tile_pad = tile_pad\n",
        "        self.pre_pad = pre_pad\n",
        "        self.mod_scale = None\n",
        "        self.half = half\n",
        "\n",
        "        # initialize model\n",
        "        if gpu_id:\n",
        "            self.device = torch.device(\n",
        "                f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
        "        else:\n",
        "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
        "        # if the model_path starts with https, it will first download models to the folder: realesrgan/weights\n",
        "        # if model_path.startswith('https://'):\n",
        "        #     model_path = load_file_from_url(\n",
        "        #         url=model_path, model_dir='realesrgan/weights')\n",
        "        loadnet = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "        # prefer to use params_ema\n",
        "        if 'params_ema' in loadnet:\n",
        "            keyname = 'params_ema'\n",
        "        else:\n",
        "            keyname = 'params'\n",
        "        model.load_state_dict(loadnet[keyname], strict=True)\n",
        "        model.eval()\n",
        "        self.model = model.to(self.device)\n",
        "        if self.half:\n",
        "            self.model = self.model.half()\n",
        "\n",
        "    def pre_process(self, img):\n",
        "        \"\"\"Pre-process, such as pre-pad and mod pad, so that the images can be divisible\n",
        "        \"\"\"\n",
        "        img = torch.from_numpy(np.transpose(img, (2, 0, 1))).float()\n",
        "        self.img = img.unsqueeze(0).to(self.device)\n",
        "        if self.half:\n",
        "            self.img = self.img.half()\n",
        "\n",
        "        # pre_pad\n",
        "        if self.pre_pad != 0:\n",
        "            self.img = F.pad(self.img, (0, self.pre_pad, 0, self.pre_pad), 'reflect')\n",
        "        # mod pad for divisible borders\n",
        "        if self.scale == 2:\n",
        "            self.mod_scale = 2\n",
        "        elif self.scale == 1:\n",
        "            self.mod_scale = 4\n",
        "        if self.mod_scale is not None:\n",
        "            self.mod_pad_h, self.mod_pad_w = 0, 0\n",
        "            _, _, h, w = self.img.size()\n",
        "            if (h % self.mod_scale != 0):\n",
        "                self.mod_pad_h = (self.mod_scale - h % self.mod_scale)\n",
        "            if (w % self.mod_scale != 0):\n",
        "                self.mod_pad_w = (self.mod_scale - w % self.mod_scale)\n",
        "            self.img = F.pad(self.img, (0, self.mod_pad_w, 0, self.mod_pad_h), 'reflect')\n",
        "\n",
        "    def process(self):\n",
        "        # model inference\n",
        "        self.output = self.model(self.img)\n",
        "\n",
        "    def tile_process(self):\n",
        "        \"\"\"It will first crop input images to tiles, and then process each tile.\n",
        "        Finally, all the processed tiles are merged into one images.\n",
        "\n",
        "        Modified from: https://github.com/ata4/esrgan-launcher\n",
        "        \"\"\"\n",
        "        batch, channel, height, width = self.img.shape\n",
        "        output_height = height * self.scale\n",
        "        output_width = width * self.scale\n",
        "        output_shape = (batch, channel, output_height, output_width)\n",
        "\n",
        "        # start with black image\n",
        "        self.output = self.img.new_zeros(output_shape)\n",
        "        tiles_x = math.ceil(width / self.tile_size)\n",
        "        tiles_y = math.ceil(height / self.tile_size)\n",
        "\n",
        "        # loop over all tiles\n",
        "        for y in range(tiles_y):\n",
        "            for x in range(tiles_x):\n",
        "                # extract tile from input image\n",
        "                ofs_x = x * self.tile_size\n",
        "                ofs_y = y * self.tile_size\n",
        "                # input tile area on total image\n",
        "                input_start_x = ofs_x\n",
        "                input_end_x = min(ofs_x + self.tile_size, width)\n",
        "                input_start_y = ofs_y\n",
        "                input_end_y = min(ofs_y + self.tile_size, height)\n",
        "\n",
        "                # input tile area on total image with padding\n",
        "                input_start_x_pad = max(input_start_x - self.tile_pad, 0)\n",
        "                input_end_x_pad = min(input_end_x + self.tile_pad, width)\n",
        "                input_start_y_pad = max(input_start_y - self.tile_pad, 0)\n",
        "                input_end_y_pad = min(input_end_y + self.tile_pad, height)\n",
        "\n",
        "                # input tile dimensions\n",
        "                input_tile_width = input_end_x - input_start_x\n",
        "                input_tile_height = input_end_y - input_start_y\n",
        "                tile_idx = y * tiles_x + x + 1\n",
        "                input_tile = self.img[:, :, input_start_y_pad:input_end_y_pad, input_start_x_pad:input_end_x_pad]\n",
        "\n",
        "                # upscale tile\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        output_tile = self.model(input_tile)\n",
        "                except RuntimeError as error:\n",
        "                    print('Error', error)\n",
        "                print(f'\\tTile {tile_idx}/{tiles_x * tiles_y}')\n",
        "\n",
        "                # output tile area on total image\n",
        "                output_start_x = input_start_x * self.scale\n",
        "                output_end_x = input_end_x * self.scale\n",
        "                output_start_y = input_start_y * self.scale\n",
        "                output_end_y = input_end_y * self.scale\n",
        "\n",
        "                # output tile area without padding\n",
        "                output_start_x_tile = (input_start_x - input_start_x_pad) * self.scale\n",
        "                output_end_x_tile = output_start_x_tile + input_tile_width * self.scale\n",
        "                output_start_y_tile = (input_start_y - input_start_y_pad) * self.scale\n",
        "                output_end_y_tile = output_start_y_tile + input_tile_height * self.scale\n",
        "\n",
        "                # put tile into output image\n",
        "                self.output[:, :, output_start_y:output_end_y,\n",
        "                            output_start_x:output_end_x] = output_tile[:, :, output_start_y_tile:output_end_y_tile,\n",
        "                                                                       output_start_x_tile:output_end_x_tile]\n",
        "\n",
        "    def post_process(self):\n",
        "        # remove extra pad\n",
        "        if self.mod_scale is not None:\n",
        "            _, _, h, w = self.output.size()\n",
        "            self.output = self.output[:, :, 0:h - self.mod_pad_h * self.scale, 0:w - self.mod_pad_w * self.scale]\n",
        "        # remove prepad\n",
        "        if self.pre_pad != 0:\n",
        "            _, _, h, w = self.output.size()\n",
        "            self.output = self.output[:, :, 0:h - self.pre_pad * self.scale, 0:w - self.pre_pad * self.scale]\n",
        "        return self.output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def enhance(self, img, outscale=None, alpha_upsampler='realesrgan'):\n",
        "        h_input, w_input = img.shape[0:2]\n",
        "        # img: numpy\n",
        "        img = img.astype(np.float32)\n",
        "        if np.max(img) > 256:  # 16-bit image\n",
        "            max_range = 65535\n",
        "            print('\\tInput is a 16-bit image')\n",
        "        else:\n",
        "            max_range = 255\n",
        "        img = img / max_range\n",
        "        if len(img.shape) == 2:  # gray image\n",
        "            img_mode = 'L'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "        elif img.shape[2] == 4:  # RGBA image with alpha channel\n",
        "            img_mode = 'RGBA'\n",
        "            alpha = img[:, :, 3]\n",
        "            img = img[:, :, 0:3]\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                alpha = cv2.cvtColor(alpha, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            img_mode = 'RGB'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ------------------- process image (without the alpha channel) ------------------- #\n",
        "        self.pre_process(img)\n",
        "        if self.tile_size > 0:\n",
        "            self.tile_process()\n",
        "        else:\n",
        "            self.process()\n",
        "        output_img = self.post_process()\n",
        "        output_img = output_img.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "        output_img = np.transpose(output_img[[2, 1, 0], :, :], (1, 2, 0))\n",
        "        if img_mode == 'L':\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # ------------------- process the alpha channel if necessary ------------------- #\n",
        "        if img_mode == 'RGBA':\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                self.pre_process(alpha)\n",
        "                if self.tile_size > 0:\n",
        "                    self.tile_process()\n",
        "                else:\n",
        "                    self.process()\n",
        "                output_alpha = self.post_process()\n",
        "                output_alpha = output_alpha.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "                output_alpha = np.transpose(output_alpha[[2, 1, 0], :, :], (1, 2, 0))\n",
        "                output_alpha = cv2.cvtColor(output_alpha, cv2.COLOR_BGR2GRAY)\n",
        "            else:  # use the cv2 resize for alpha channel\n",
        "                h, w = alpha.shape[0:2]\n",
        "                output_alpha = cv2.resize(alpha, (w * self.scale, h * self.scale), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            # merge the alpha channel\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2BGRA)\n",
        "            output_img[:, :, 3] = output_alpha\n",
        "\n",
        "        # ------------------------------ return ------------------------------ #\n",
        "        if max_range == 65535:  # 16-bit image\n",
        "            output = (output_img * 65535.0).round().astype(np.uint16)\n",
        "        else:\n",
        "            output = (output_img * 255.0).round().astype(np.uint8)\n",
        "\n",
        "        if outscale is not None and outscale != float(self.scale):\n",
        "            output = cv2.resize(\n",
        "                output, (\n",
        "                    int(w_input * outscale),\n",
        "                    int(h_input * outscale),\n",
        "                ), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "        return output, img_mode\n",
        "\n",
        "\n",
        "class PrefetchReader(threading.Thread):\n",
        "    \"\"\"Prefetch images.\n",
        "\n",
        "    Args:\n",
        "        img_list (list[str]): A image list of image paths to be read.\n",
        "        num_prefetch_queue (int): Number of prefetch queue.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_list, num_prefetch_queue):\n",
        "        super().__init__()\n",
        "        self.que = queue.Queue(num_prefetch_queue)\n",
        "        self.img_list = img_list\n",
        "\n",
        "    def run(self):\n",
        "        for img_path in self.img_list:\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            self.que.put(img)\n",
        "\n",
        "        self.que.put(None)\n",
        "\n",
        "    def __next__(self):\n",
        "        next_item = self.que.get()\n",
        "        if next_item is None:\n",
        "            raise StopIteration\n",
        "        return next_item\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "\n",
        "class IOConsumer(threading.Thread):\n",
        "\n",
        "    def __init__(self, opt, que, qid):\n",
        "        super().__init__()\n",
        "        self._queue = que\n",
        "        self.qid = qid\n",
        "        self.opt = opt\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            msg = self._queue.get()\n",
        "            if isinstance(msg, str) and msg == 'quit':\n",
        "                break\n",
        "\n",
        "            output = msg['output']\n",
        "            save_path = msg['save_path']\n",
        "            cv2.imwrite(save_path, output)\n",
        "        print(f'IO worker {self.qid} is done.')\n",
        "\n",
        "\n",
        "def FileExtension(FileName):\n",
        "  return FileName.split(\".\")[-1]\n",
        "\n",
        "#@title Main Code\n",
        "# And this is the main method to use to enhance our images:\n",
        "def enhance_image(input_file, layers=2, upscale=2, final_filename=\"\", enhance_faces=False):\n",
        "  ## Set models to use\n",
        "  if layers == 4:\n",
        "    # 4 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "    netscale = 4\n",
        "    model_file = 'RealESRGAN_x4plus.pth'\n",
        "  elif layers == 2:\n",
        "    # 2 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
        "    netscale = 2\n",
        "    model_file = 'RealESRGAN_x2plus.pth'\n",
        "  else:\n",
        "    print(\"Layers parameter must be either 2 or 4.\")\n",
        "    return\n",
        "  # Final enhanced image will be upscaled by this factor using LANCZOS4 resampling\n",
        "  # Input image\n",
        "  imgname, org_extension = input_file.split('.')\n",
        "  image = cv2.imread(input_file)\n",
        "  org_width, org_height = image.shape[:2]\n",
        "  # Compute tile size\n",
        "  if min(org_width, org_height) <= 800:\n",
        "    tile_size = 0\n",
        "    print(f\"Small image so batching is not necessary.\")\n",
        "  else:\n",
        "    tile_size = ceil(sqrt(min(org_width, org_height))) * 10\n",
        "  if tile_size > 500:\n",
        "    tile_size = 350\n",
        "  print(f\"Tile size being used: {tile_size}\")\n",
        "  # restorer\n",
        "  upsampler = RealESRGANer(\n",
        "      scale=netscale,\n",
        "      model_path=model_file,\n",
        "      model=model,\n",
        "      tile=tile_size,\n",
        "      tile_pad=2,\n",
        "      half=False)\n",
        "  # Use GFPGAN for face enhancement\n",
        "  if enhance_faces:\n",
        "    from gfpgan import GFPGANer\n",
        "    face_enhancer = GFPGANer(\n",
        "        model_path='GFPGANv1.4.pth',\n",
        "        upscale=upscale,\n",
        "        arch='clean',\n",
        "        channel_multiplier=2,\n",
        "        bg_upsampler=upsampler)\n",
        "  img = cv2.imread(input_file, cv2.IMREAD_UNCHANGED)\n",
        "  try:\n",
        "    if enhance_faces:\n",
        "      _, _, output = face_enhancer.enhance(img, has_aligned=False, only_center_face=False, paste_back=True)\n",
        "    else:\n",
        "      output, _ = upsampler.enhance(img, outscale=upscale)\n",
        "  except RuntimeError as error:\n",
        "      print('Error', error)\n",
        "      print('If you encounter CUDA out of memory, try to set --tile with a smaller number.')\n",
        "      print('Else, the file you are using may be too large.')\n",
        "  else:\n",
        "    if final_filename != \"\":\n",
        "      save_path = final_filename\n",
        "    else:\n",
        "      save_path = f'{imgname}_out.{FileExtension(input_file)}'\n",
        "    cv2.imwrite(save_path, output)\n",
        "    print(f\"Enhanced image has been saved to {save_path}.\\nClick refresh button on the left panel to get latest version of {save_path}\")\n",
        "    return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Metrics Code\n",
        "# These are some helper fucntions to compute the quality of images based on certain metrics like resolution, sharpness, contrast, and noise:\n",
        "def get_resolution(image):\n",
        "    return image.shape[:2]\n",
        "\n",
        "def get_noise_level(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute the Discrete Fourier Transform (DFT)\n",
        "    f_transform = np.fft.fft2(gray)\n",
        "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "\n",
        "    # Compute the magnitude spectrum\n",
        "    magnitude_spectrum = np.abs(f_transform_shifted)\n",
        "\n",
        "    # Calculate the noise level using the standard deviation of the magnitude spectrum\n",
        "    noise_level = np.std(np.log1p(magnitude_spectrum))\n",
        "\n",
        "    return round(noise_level, 2)\n",
        "\n",
        "def get_sharpness(image):\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    # Apply an edge-enhancing filter (Laplacian) and compute variance as a measure of sharpness\n",
        "    laplacian = cv2.Laplacian(cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2GRAY), cv2.CV_64F)\n",
        "    return round(laplacian.var(), 2)\n",
        "\n",
        "def get_contrast(image):\n",
        "    # Using Michelson contrast measure\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    I_max = np.max(gray)\n",
        "    I_min = np.min(gray)\n",
        "    print(I_min, I_max)\n",
        "\n",
        "    contrast = (I_max - I_min) / (I_max + I_min)\n",
        "    return round(contrast, 5)\n",
        "\n",
        "\n",
        "def get_filesize(image_file):\n",
        "  file_size = os.path.getsize(image_file)\n",
        "  return round(file_size / 1_000_000, 2)\n",
        "\n",
        "\n",
        "import time\n",
        "class Timer:\n",
        "    def __init__(self) -> None:\n",
        "        self.start = 0\n",
        "        self.end = 0\n",
        "\n",
        "    def start(self):\n",
        "        self.start = time.time()\n",
        "\n",
        "    def end(self):\n",
        "        self.end = time.time()\n",
        "        elapsed_time = self.end - self.start\n",
        "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
        "\n",
        "\n",
        "def print_quality(image_file):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_file)\n",
        "\n",
        "    # Get image metrics\n",
        "    resolution = get_resolution(image)\n",
        "    noise_level = get_noise_level(image)\n",
        "    sharpness = get_sharpness(image)\n",
        "    try:\n",
        "      contrast = get_contrast(image)\n",
        "    except:\n",
        "      contrast = \"unknown\"\n",
        "    image_size = get_filesize(image_file)\n",
        "\n",
        "    # Output the results\n",
        "    print(f\"Resolution: {resolution} pixels\")\n",
        "    print(f\"Noise Level: {noise_level} dB\")\n",
        "    print(f\"Sharpness: {sharpness}\")\n",
        "    print(f\"Contrast: {contrast}\")\n",
        "    print(f\"Size of image: {image_size} MB\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YCTQmvlNFY91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Here we go woohoo :)\n",
        "#@markdown Ok so now you can run the code cell below and scroll a little down to below the code cell. It will prompt you to upload an image file. After it is uploaded, it will enhance your image and display it for you.\n",
        "#@markdown\n",
        "#@markdown You can change the values of \"layers\" and \"enhance_faces\" in the actual method below which has been cordoned off for you! ;)\n",
        "\n",
        "MergeSessionsPath = \"/content/drive/MyDrive/UpscaleVideo/MergeSessions\"\n",
        "OriginalOutputPath = \"/content/OriginalOutput\"\n",
        "UpscaledOutputPath = \"/content/drive/MyDrive/UpscaleVideo/UpscaledOutput\"\n",
        "\n",
        "\n",
        "\n",
        "%cd /content\n",
        "Model = 'RealESRGAN_x2plus.pth (default) (For General Images)' # @param [\"RealESRGAN_x2plus.pth (default) (For General Images)\", \"RealESRGAN_x4plus.pth (For General Images)\", \"RealESRNet_x4plus.pth (X4 model with MSE loss (over-smooth effects))\", \"ESRGAN_SRx4_DF2KOST_official-ff704c30.pth (official ESRGAN model)\", \"RealESRGAN_x4plus_netD.pth (fine-tuning)\", \"RealESRGAN_x2plus_netD.pth (fine-tuning)\", \"RealESRGAN_x4plus_anime_6B.pth (for anime images)\", \"RealESRGAN_x4plus_anime_6B_netD.pth (fine-tuning anime images)\", \"realesr-animevideov3.pth (For Animation Videos)\"]\n",
        "#@markdown Choose either 2 or 4 as the value here.\n",
        "layers = 2 # @param [2, 4]\n",
        "#@markdown This value indicates the number of times the output image's resolution needs to enlarged from the original.\n",
        "upscale = 2 # @param {type:\"number\"}\n",
        "#@markdown I honestly don't know what this does. enhance the faces of the characters?\n",
        "enhance_faces=True # @param {type:\"boolean\"}\n",
        "Display_Images=True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown This says how many images to transfer to other sessions at once.\n",
        "Queue = 10 # @param {type:\"integer\"}\n",
        "\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "global images\n",
        "\n",
        "def RemoveNumbersFromString(string):\n",
        "  returnString = \"\"\n",
        "  for char in string:\n",
        "    if(not char.isnumeric()):\n",
        "      returnString = returnString + char\n",
        "  return returnString\n",
        "\n",
        "def DeleteDriveRootNonsense():\n",
        "  global images\n",
        "  DriveRootList = listdir2(\"/content/drive/MyDrive\")\n",
        "  DeleteList = [f\".{FileExtension(images[0])}\",f\" ().{FileExtension(images[0])}\",f\"_upscaled.{FileExtension(images[0])}\",f\"_upscaled ().{FileExtension(images[0])}\",\"SessionNamesToDo\",\"SessionNamesToDo ()\",\"SessionTaken ().txt\",\"SessionTaken.txt\",\"ToProcess\",\"ToProcess ()\",\"MergeSessions\",\"MergeSessions ()\"]\n",
        "  for item in DriveRootList:\n",
        "    if(RemoveNumbersFromString(item) in DeleteList):\n",
        "      if(os.path.isdir(f\"/content/drive/MyDrive/{item}\")):\n",
        "        shutil.rmtree(f\"/content/drive/MyDrive/{item}\")\n",
        "      if(os.path.isfile(f\"/content/drive/MyDrive/{item}\")):\n",
        "        os.remove(f\"/content/drive/MyDrive/{item}\")\n",
        "\n",
        "def DisplayImage(imagePath):\n",
        "  img = mpimg.imread(imagePath)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def enhanceImage2(filename, outputFilename, layers, upscale, enhance_faces):\n",
        "  # Start timing\n",
        "  t = Timer()\n",
        "  t.start\n",
        "  ########################################################################################################################################################\n",
        "  result = enhance_image(input_file=filename, layers=layers, upscale=upscale, final_filename=outputFilename, enhance_faces=enhance_faces)\n",
        "  ########################################################################################################################################################\n",
        "  print(f\"result: {result}\")\n",
        "  t.end # End timing\n",
        "  ending = result.split(\".\")[1]\n",
        "  output = outputFilename\n",
        "  if(Display_Images):\n",
        "    print(filename)\n",
        "    DisplayImage(filename)\n",
        "    print(output)\n",
        "    DisplayImage(output)\n",
        "\n",
        "def NumberOfImage(ImageName):\n",
        "  returnNumber = \"\"\n",
        "  for x in ImageName:\n",
        "    if(x.isnumeric()):\n",
        "     returnNumber = returnNumber + x\n",
        "  return int(returnNumber)\n",
        "\n",
        "def GetImageOn():\n",
        "  imagesDone = os.listdir(UpscaledOutputPath)\n",
        "  imagesDone.sort()\n",
        "  returnNumber = 0\n",
        "  x = 1\n",
        "  while(x < len(imagesDone) -1):\n",
        "    if(NumberOfImage(imagesDone[x]) < NumberOfImage(imagesDone[x+1])-1):\n",
        "      returnNumber = NumberOfImage(imagesDone[x])\n",
        "      break\n",
        "    x = x + 1\n",
        "  return returnNumber\n",
        "\n",
        "def listdir2(directoryToList):\n",
        "  returnList = []\n",
        "  if(os.path.exists(directoryToList)):\n",
        "    listOfDir = os.listdir(directoryToList)\n",
        "    listOfDir.sort()\n",
        "    returnList = []\n",
        "    for thing in listOfDir:\n",
        "      if(os.path.isfile(f\"{directoryToList}/{thing}\")):\n",
        "        returnList.append(thing)\n",
        "      if(os.path.isdir(f\"{directoryToList}/{thing}\")):\n",
        "        if(not thing == \".ipynb_checkpoints\"):\n",
        "          returnList.append(thing)\n",
        "        else:\n",
        "          !rm -r {directoryToList}/{thing}\n",
        "  return returnList\n",
        "\n",
        "def ImageExistsElsewhere(ImageName):\n",
        "  returnValue = False\n",
        "  global images\n",
        "  sessionsAvailable = listdir2(f\"{MergeSessionsPath}/ToProcess\")\n",
        "  NumberOfAssistSessionsAvailable = len(listdir2(f\"{MergeSessionsPath}/ToProcess\"))\n",
        "  if(NumberOfAssistSessionsAvailable > 0):\n",
        "    for session in sessionsAvailable:\n",
        "      if(os.path.exists(f\"{MergeSessionsPath}/ToProcess/{session}/{ImageName}\")):\n",
        "        returnValue = True\n",
        "  if(os.path.exists(f\"{UpscaledOutputPath}/{ImageName.replace('.','_upscaled.')}\")):\n",
        "    returnValue = True\n",
        "  return returnValue\n",
        "\n",
        "def ProgressBar(number_on,final,units=100):\n",
        "  percent = round((round(number_on)/round(final))*100,2)\n",
        "  returnText = f\"{percent}% : [\"\n",
        "  new_number_on = round((units*(number_on/final)))\n",
        "  for x in range(new_number_on):\n",
        "    returnText = returnText + \"â–ˆ\"\n",
        "  for x in range(units-new_number_on):\n",
        "    returnText = returnText + \"_\"\n",
        "  returnText = returnText + \"]\"\n",
        "  return returnText\n",
        "\n",
        "def setup():\n",
        "  session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "  if(session == 1):\n",
        "    if(not os.path.exists(f\"{MergeSessionsPath}/setup\")):\n",
        "      os.makedirs(f\"{MergeSessionsPath}/setup\")\n",
        "    if(not os.path.exists(f\"{MergeSessionsPath}/MasterSessionTaken.txt\")):\n",
        "      print()\n",
        "      print()\n",
        "      print(\"MergeSessionsPath/setup contains this:\")\n",
        "      print()\n",
        "      print(os.listdir(f\"{MergeSessionsPath}\"))\n",
        "      f = open(f\"{MergeSessionsPath}/MasterSessionTaken.txt\", \"w\")\n",
        "      f.close()\n",
        "      print(f\"SESSION IS: {session}, AKA the master session.\")\n",
        "      print()\n",
        "      print()\n",
        "      print(\"After establishing session, MergeSessionsPath contains this:\")\n",
        "      print()\n",
        "      print(os.listdir(f\"{MergeSessionsPath}\"))\n",
        "  else:\n",
        "    if(not os.path.exists(f\"{MergeSessionsPath}/setup/Session{session}Taken.txt\")):\n",
        "      x = 2\n",
        "      while(os.path.exists(f\"{MergeSessionsPath}/setup/Session{x}Taken.txt\")):\n",
        "        x = x + 1\n",
        "      print()\n",
        "      print()\n",
        "      print(\"MergeSessionsPath/setup contains this:\")\n",
        "      print()\n",
        "      print(os.listdir(f\"{MergeSessionsPath}/setup\"))\n",
        "      f = open(f\"{MergeSessionsPath}/setup/Session{x}Taken.txt\", \"w\")\n",
        "      f.close()\n",
        "      session = x\n",
        "      open(\"/content/sessionNumber.txt\",\"w\").write(str(session))\n",
        "      print(f\"SESSION IS {session} AKA an assist session.\")\n",
        "      print()\n",
        "      print()\n",
        "      print(\"After establishing session, MergeSessionsPath/setup contains this:\")\n",
        "      print()\n",
        "      print(os.listdir(f\"{MergeSessionsPath}/setup\"))\n",
        "\n",
        "\n",
        "def main():\n",
        "  setup()\n",
        "  %cd /content\n",
        "  if(Model == 'RealESRGAN_x2plus.pth (default) (For General Images)' and (not os.path.exists(\"/content/RealESRGAN_x2plus.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth\n",
        "  if(Model == 'RealESRGAN_x4plus.pth (For General Images)' and (not os.path.exists(\"//content/RealESRGAN_x4plus.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
        "  if(Model == 'RealESRNet_x4plus.pth (X4 model with MSE loss (over-smooth effects))' and (not os.path.exists(\"/RealESRNet_x4plus.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.1/RealESRNet_x4plus.pth\n",
        "  if(Model == 'ESRGAN_SRx4_DF2KOST_official-ff704c30.pth (official ESRGAN model)' and (not os.path.exists(\"/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.1/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth\n",
        "  if(Model == 'RealESRGAN_x4plus_netD.pth (fine-tuning)' and (not os.path.exists(\"/RealESRGAN_x4plus_netD.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.3/RealESRGAN_x4plus_netD.pth\n",
        "  if(Model == 'RealESRGAN_x2plus_netD.pth (fine-tuning)' and (not os.path.exists(\"/RealESRGAN_x2plus_netD.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.3/RealESRGAN_x2plus_netD.pth\n",
        "  if(Model == 'RealESRGAN_x4plus_anime_6B.pth (for anime images)' and (not os.path.exists(\"/RealESRGAN_x4plus_anime_6B.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\n",
        "  if(Model == 'RealESRGAN_x4plus_anime_6B_netD.pth (fine-tuning anime images)' and (not os.path.exists(\"/RealESRGAN_x4plus_anime_6B_netD.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B_netD.pth\n",
        "  if(Model == 'realesr-animevideov3.pth (For Animation Videos)' and (not os.path.exists(\"/realesr-animevideov3.pth\"))):\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-animevideov3.pth\n",
        "\n",
        "  if(not os.path.exists(\"/content/GFPGANv1.4.pth\")):\n",
        "    !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\n",
        "\n",
        "\n",
        "\n",
        "  if(not os.path.exists(UpscaledOutputPath)):\n",
        "    os.makedirs(UpscaledOutputPath)\n",
        "\n",
        "  session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "  if(session == 1):\n",
        "    print(\"THIS IS THE MASTER SESSION.\")\n",
        "    global images\n",
        "    images = os.listdir(OriginalOutputPath)\n",
        "    images.sort()\n",
        "    fullAmount = len(images)\n",
        "    imageOn = GetImageOn()\n",
        "    x = imageOn\n",
        "    while(x < fullAmount):\n",
        "      filename = images[x]\n",
        "      if(not ImageExistsElsewhere(filename)):\n",
        "        #Checks to see if there are any other sessions running that are linked.\n",
        "        if(os.path.exists(f\"{MergeSessionsPath}/ToProcess\")):\n",
        "          assistSessionsAvailable = listdir2(f\"{MergeSessionsPath}/ToProcess\")\n",
        "          NumberOfAssistSessionsAvailable = len(listdir2(f\"{MergeSessionsPath}/ToProcess\"))\n",
        "          #Checks to see if there are any other sessions running that are linked.\n",
        "          if(NumberOfAssistSessionsAvailable > 0):\n",
        "            #Goes through all of the colab sessions that are running.\n",
        "            #NOTE: session2 does NOT mean the 2nd session. It means the name of the session folder.\n",
        "            for session2 in assistSessionsAvailable:\n",
        "              #Checks to see if the colab session is free, and has no images to process.\n",
        "              if(len(listdir2(f\"{MergeSessionsPath}/ToProcess/{session2}\")) < 1):\n",
        "                #Moves the next Queue images that need to be processed, to the free session to process\n",
        "                #Note: This does not move the image itself. It just moves the NAME of the image. This speeds up the runtime.\n",
        "                print(f\"Moving {Queue} images to alternate session, named: {session2}\")\n",
        "                x2 = 0\n",
        "                while(x2 < Queue):\n",
        "                  filename = images[x]\n",
        "                  if(not ImageExistsElsewhere(filename)):\n",
        "                    print(filename)\n",
        "                    f = open(f\"{MergeSessionsPath}/ToProcess/{session2}/{filename}\",\"w\")\n",
        "                    f.close()\n",
        "                    x2 = x2 + 1\n",
        "                  x = x + 1\n",
        "        filename = images[x]\n",
        "        if(not ImageExistsElsewhere(filename)):\n",
        "          print(f\"processing: {filename}\")\n",
        "          DeleteDriveRootNonsense()\n",
        "          enhanceImage2(f\"{OriginalOutputPath}/{filename}\",f\"{UpscaledOutputPath}/{filename.replace('.','_upscaled.')}\",layers,upscale,enhance_faces)\n",
        "          print(f\"{ProgressBar(x,fullAmount,40)} {x}/{fullAmount}\")\n",
        "      x = x + 1\n",
        "    print(\"FINISHED with main program.\")\n",
        "    print(\"Checking for missing frames, and processing them.\")\n",
        "    for image in images:\n",
        "      if(not os.path.exists(f\"{UpscaledOutputPath}/{image.replace('.','_upscaled.')}\")):\n",
        "        print(f\"processing: {image}}\")\n",
        "        enhanceImage2(f\"{OriginalOutputPath}/{image}\",f\"{UpscaledOutputPath}/{image.replace('.','_upscaled.')}\",layers,upscale,enhance_faces)\n",
        "  else:\n",
        "    print(f\"Session is {session}, an assist session\")\n",
        "    while(os.path.exists(f\"{MergeSessionsPath}/MasterSessionTaken.txt\")):\n",
        "      if(not os.path.exists(f\"{MergeSessionsPath}/ToProcess/Session{session}NamesToDo\")):\n",
        "        os.makedirs(f\"{MergeSessionsPath}/ToProcess/Session{session}NamesToDo\")\n",
        "      print(\"\\r\",f\"Waiting for folder: \\\"{MergeSessionsPath}/ToProcess/Session{session}NamesToDo\\\" to be filled with a queue.\", end=\"\")\n",
        "      images = os.listdir(f\"{MergeSessionsPath}/ToProcess/Session{session}NamesToDo\")\n",
        "      images.sort()\n",
        "      if(len(images) > 0):\n",
        "        print()\n",
        "        print(\"INFORMATION: RECEIVED INPUT!!! Hooray!\")\n",
        "        for image2 in images:\n",
        "          print(f\"processing {image2}\")\n",
        "          DeleteDriveRootNonsense()\n",
        "          enhanceImage2(f\"{OriginalOutputPath}/{image2}\",f\"{UpscaledOutputPath}/{image2.replace('.','_upscaled.')}\",layers,upscale,enhance_faces)\n",
        "          !rm {MergeSessionsPath}/ToProcess/Session{session}NamesToDo/{image2}\n",
        "    print(\"Detected Master session has been stopped. Deleting queue directory.\")\n",
        "    !rm -r {MergeSessionsPath}/ToProcess/Session{session}NamesToDo\n",
        "    print(\"Deleting session taken file.\")\n",
        "    !rm {MergeSessionsPath}/setup/Session{session}Taken.txt\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  main()\n",
        "except KeyboardInterrupt:\n",
        "  print('Interrupted')\n",
        "  session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "  if(session > 1):\n",
        "    !rm {MergeSessionsPath}/setup/Session{session}Taken.txt\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated this colab notebook. Sending message to main notebook it is closed.\")\n",
        "  else:\n",
        "    !rm {MergeSessionsPath}/MasterSessionTaken.txt\n",
        "    !rm -r {MergeSessionsPath}/setup\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated the main colab notebook. Terminating all others...\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IJdOMdNDGWiM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Finalize by merging all frames into one video, and adding audio back.\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "MergeSessionsPath = \"/content/drive/MyDrive/UpscaleVideo/MergeSessions\"\n",
        "OriginalOutputPath = \"/content/OriginalOutput\"\n",
        "UpscaledOutputPath = \"/content/drive/MyDrive/UpscaleVideo/UpscaledOutput\"\n",
        "\n",
        "\n",
        "\n",
        "def ProgressBar(number_on,final,units=100):\n",
        "  percent = round((round(number_on)/round(final))*100,2)\n",
        "  returnText = f\"{percent}% : [\"\n",
        "  new_number_on = round((units*(number_on/final)))\n",
        "  for x in range(new_number_on):\n",
        "    returnText = returnText + \"â–ˆ\"\n",
        "  for x in range(units-new_number_on):\n",
        "    returnText = returnText + \"_\"\n",
        "  returnText = returnText + \"]\"\n",
        "  return returnText\n",
        "\n",
        "\n",
        "\n",
        "session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "if(session == 1):\n",
        "  print(\"reading saved framerate from the first cell.\")\n",
        "  FrameRate = int(open(\"/content/drive/MyDrive/UpscaleVideo/Framerate.txt\",\"r\").read())\n",
        "  %cd /content/drive/MyDrive/UpscaleVideo/UpscaledOutput\n",
        "\n",
        "  frameNames = os.listdir(UpscaledOutputPath) # Get list of file names\n",
        "  frameNames.sort()\n",
        "  print(\"Getting width and height.\")\n",
        "  #get width and height of first frame\n",
        "  height, width, _ = cv2.imread(f\"{UpscaledOutputPath}/{frameNames[0]}\").shape\n",
        "  #Start the thing.\n",
        "  print(\"Combining frames into video. But no audio yet.\")\n",
        "  out = cv2.VideoWriter('/content/drive/MyDrive/UpscaleVideo/EnhancedFramesOnly.mp4', cv2.VideoWriter_fourcc(*'mp4v'), FrameRate, (width, height))\n",
        "  x = 0\n",
        "  lenframeNames = len(frameNames)\n",
        "  while(x < lenframeNames):\n",
        "    frameName = frameNames[x]\n",
        "    print(\"\\r\",f\"adding: {frameName} {ProgressBar(x,lenframeNames,50)} {x}/{lenframeNames}\", end=\"\")\n",
        "    frame = cv2.imread(f\"{UpscaledOutputPath}/{frameName}\")\n",
        "    out.write(frame)\n",
        "    x = x + 1\n",
        "  out.release()\n",
        "\n",
        "  OriginalVideo = \"/content/drive/MyDrive/UpscaleVideo/EnhancedFramesOnly.mp4\"\n",
        "  OriginalAudio = \"/content/drive/MyDrive/UpscaleVideo/audio.wav\"\n",
        "  NewVideo = \"/content/drive/MyDrive/UpscaleVideo/output.mp4\"\n",
        "  !rm {NewVideo}\n",
        "\n",
        "  !pip install moviepy==1.0.3\n",
        "\n",
        "  # Import everything needed to edit video clips\n",
        "  from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\n",
        "\n",
        "  # Load my video\n",
        "  video = VideoFileClip(OriginalVideo)\n",
        "\n",
        "  # Load my audio\n",
        "  audio_clip = AudioFileClip(OriginalAudio)\n",
        "\n",
        "  # Add the audio to the video\n",
        "  final_video = video.set_audio(audio_clip)\n",
        "\n",
        "  # Write the result to a file (many options available !)\n",
        "  final_video.write_videofile(NewVideo)"
      ],
      "metadata": {
        "id": "EHqSSwDIUH2G",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Terminate session\n",
        "Terminate_Session=False # @param {type:\"boolean\"}\n",
        "\n",
        "if(Terminate_Session):\n",
        "  print('Interrupted')\n",
        "  session = int(open(\"/content/sessionNumber.txt\",\"r\").read())\n",
        "  if(session > 1):\n",
        "    !rm {MergeSessionsPath}/setup/Session{session}Taken.txt\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated this colab notebook. Sending message to main notebook it is closed.\")\n",
        "  else:\n",
        "    !rm {MergeSessionsPath}/MasterSessionTaken.txt\n",
        "    !rm -r {MergeSessionsPath}/setup\n",
        "    raise Exception(\"KeyboardInterrupt: You have terminated the main colab notebook. Terminating all others...\")\n"
      ],
      "metadata": {
        "id": "ryo0Uj0fng9-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}